{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from src.clip import get_image_features, define_model, feature_dim\n",
    "from src.build_classifier import get_classifier\n",
    "from src.train_clf import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as FT\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from cifar.cifarRawCorrupted import get_original_loaders, get_corrupt_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "model, _ = define_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_loader = get_corrupt_loaders(model_name='clip', severity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,kt = next(iter(c_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 288, 288])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 640])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_features(model, u.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "clip_clf = get_classifier(640, output_classes=10, n_layers=1).to(device)\n",
    "train_loader, val_loader, test_loader = get_original_loaders(batch_size=1024, model_name='clip') \n",
    "test_corrupt_loader = get_corrupt_loaders(batch_size=1024, model_name='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(clip_clf.parameters(), lr=0.001)\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omoussa/miniconda3/envs/brn/lib/python3.9/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss 2.302623963356018 and initial accuracy 0.0981186181306839\n",
      " train loss: 2.0446340799331666, val loss: 1.7381766200065614, Train accuracy 0.6327880620956421, val accuracy 0.8375996351242065 \n",
      " train loss: 1.6625311434268952, val loss: 1.6256305932998658, Train accuracy 0.857861340045929, val accuracy 0.8709203600883484 \n",
      " train loss: 1.6100441753864287, val loss: 1.60384703874588, Train accuracy 0.880444347858429, val accuracy 0.8813077807426453 \n",
      " train loss: 1.5956449300050735, val loss: 1.5912055134773255, Train accuracy 0.8869873285293579, val accuracy 0.8912906646728516 \n"
     ]
    }
   ],
   "source": [
    "losses, accs, val_losses, val_accs = train(model, clip_clf, optim=optim, loss_fn=loss_fn,\n",
    "                                           train_loader=train_loader, val_loader=val_loader,\n",
    "                                           feature_fn=get_image_features, epochs=n_epochs, device=device) #TODO resize im in clip transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clip_clf.state_dict(), '../saved_models/clip_clf_resnet_4.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88372725\n"
     ]
    }
   ],
   "source": [
    "def get_acc(gt, preds = None):\n",
    "    if preds is not None: \n",
    "        return ((preds.argmax(1)==gt).sum()/len(preds)).cpu().numpy()\n",
    "        \n",
    "    \n",
    "    return ((preds.argmax(1)==gt).sum()/len(preds)).cpu().numpy()\n",
    "    \n",
    "\n",
    "def get_test_acc(emb_model, model, test_loader, feature_fn, device='cuda'):\n",
    "    eval_acc = []\n",
    "    eval_losses = []\n",
    "    for eval_batch in test_loader:\n",
    "        if len(eval_batch)>2:\n",
    "            _, ims, labels = eval_batch\n",
    "        else: \n",
    "            ims, labels = eval_batch\n",
    "        ims, labels = ims.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            features = feature_fn(emb_model, ims).squeeze()\n",
    "            preds = model(features)\n",
    "            val_acc = get_acc(labels.view(-1,), preds)\n",
    "        \n",
    "        eval_acc.append(val_acc)\n",
    "    \n",
    "    return np.mean(eval_acc)\n",
    "            # \n",
    "test_acc_orig = racc =  get_test_acc(model, clip_clf, test_loader, get_image_features, device=device,)\n",
    " \n",
    "print(test_acc_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupts_dict = {}\n",
    "corrupt_g_acc = []\n",
    "for cr in ['gaussian_noise', 'speckle_noise', 'impulse_noise', 'shot_noise', ]:\n",
    "    corrupts_dict[cr] = {}\n",
    "    for sev in [1, 2, 3, 4, 5]:\n",
    "        test_loader_corrupt = get_corrupt_loaders(batch_size=1024, corruption_type=cr, severity=sev, model_name='clip')\n",
    "        acc =  get_test_acc(model, clip_clf, test_loader_corrupt, get_image_features, device=device,)\n",
    "                                \n",
    "\n",
    "        corrupts_dict[cr][sev]=acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussian_noise': {1: 0.7270528,\n",
       "  2: 0.5826969,\n",
       "  3: 0.44952568,\n",
       "  4: 0.3876395,\n",
       "  5: 0.33660913},\n",
       " 'speckle_noise': {1: 0.7966956,\n",
       "  2: 0.6757573,\n",
       "  3: 0.6117407,\n",
       "  4: 0.49331355,\n",
       "  5: 0.39814055},\n",
       " 'impulse_noise': {1: 0.7782346,\n",
       "  2: 0.700562,\n",
       "  3: 0.6367865,\n",
       "  4: 0.51759607,\n",
       "  5: 0.42521125},\n",
       " 'shot_noise': {1: 0.78822345,\n",
       "  2: 0.71658164,\n",
       "  3: 0.53617865,\n",
       "  4: 0.4664541,\n",
       "  5: 0.36796674}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussian_noise': {1: 0.66822386,\n",
       "  2: 0.46558714,\n",
       "  3: 0.28862005,\n",
       "  4: 0.23345824,\n",
       "  5: 0.18863998},\n",
       " 'speckle_noise': {1: 0.7678073,\n",
       "  2: 0.61615515,\n",
       "  3: 0.52337176,\n",
       "  4: 0.36995178,\n",
       "  5: 0.25821707},\n",
       " 'impulse_noise': {1: 0.77613604,\n",
       "  2: 0.6875359,\n",
       "  3: 0.59512913,\n",
       "  4: 0.43106666,\n",
       "  5: 0.30344787},\n",
       " 'shot_noise': {1: 0.76686865,\n",
       "  2: 0.6564692,\n",
       "  3: 0.41788703,\n",
       "  4: 0.3300522,\n",
       "  5: 0.22840402}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupts_dict # Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussian_noise': {1: 0.8287767,\n",
       "  2: 0.68462014,\n",
       "  3: 0.52642095,\n",
       "  4: 0.45319477,\n",
       "  5: 0.39358658},\n",
       " 'speckle_noise': {1: 0.8855748,\n",
       "  2: 0.7826431,\n",
       "  3: 0.71402866,\n",
       "  4: 0.575851,\n",
       "  5: 0.4634108},\n",
       " 'impulse_noise': {1: 0.92388994,\n",
       "  2: 0.8797334,\n",
       "  3: 0.8381437,\n",
       "  4: 0.7255361,\n",
       "  5: 0.60639346},\n",
       " 'shot_noise': {1: 0.881543,\n",
       "  2: 0.8156689,\n",
       "  3: 0.6336296,\n",
       "  4: 0.5540637,\n",
       "  5: 0.42462334}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupts_dict # vitb16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussian_noise': {1: 0.8200175,\n",
       "  2: 0.6643335,\n",
       "  3: 0.5043985,\n",
       "  4: 0.42891026,\n",
       "  5: 0.37114358},\n",
       " 'speckle_noise': {1: 0.8763732,\n",
       "  2: 0.7686045,\n",
       "  3: 0.69716597,\n",
       "  4: 0.55485094,\n",
       "  5: 0.4382573},\n",
       " 'impulse_noise': {1: 0.92210215,\n",
       "  2: 0.8777124,\n",
       "  3: 0.8338388,\n",
       "  4: 0.7114158,\n",
       "  5: 0.5900191},\n",
       " 'shot_noise': {1: 0.8765625,\n",
       "  2: 0.803388,\n",
       "  3: 0.6125757,\n",
       "  4: 0.53303176,\n",
       "  5: 0.39992028}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('brn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5b4607d21dcc400ead18a1c2ca0189f0fcf8d976d586df05f937ecd8ea5ac01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
