{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from src.imagebind import get_image_features, define_model, feature_dim\n",
    "from src.build_classifier import get_classifier\n",
    "from src.train_clf import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as FT\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from cifar.cifarRawCorrupted import get_original_loaders, get_corrupt_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model = define_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_loader = get_corrupt_loaders(model_name='imagebind', severity=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "imagebind_clf = get_classifier(feature_dim, output_classes=10, n_layers=1).to(device)\n",
    "train_loader, val_loader, test_loader = get_original_loaders(batch_size=1024, model_name='blip') \n",
    "test_corrupt_loader = get_corrupt_loaders(batch_size=1024, model_name='blip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(imagebind_clf.parameters(), lr=0.001)\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omoussa/miniconda3/envs/brn/lib/python3.9/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss 2.3026005744934084 and initial accuracy 0.11320750415325165\n",
      " train loss: 2.017957925796509, val loss: 1.585170841217041, Train accuracy 0.8608154058456421, val accuracy 0.9844068288803101 \n",
      " train loss: 1.5098349273204803, val loss: 1.4875984907150268, Train accuracy 0.9857177734375, val accuracy 0.9866749048233032 \n"
     ]
    }
   ],
   "source": [
    "losses, accs, val_losses, val_accs = train(model, imagebind_clf, optim=optim, loss_fn=loss_fn,\n",
    "                                           train_loader=train_loader, val_loader=val_loader,\n",
    "                                           feature_fn=get_image_features, epochs=n_epochs, device=device) #TODO resize im in clip transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(imagebind_clf.state_dict(), '../saved_models/imagebind_clf.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986067\n"
     ]
    }
   ],
   "source": [
    "def get_acc(gt, preds = None):\n",
    "    if preds is not None: \n",
    "        return ((preds.argmax(1)==gt).sum()/len(preds)).cpu().numpy()\n",
    "        \n",
    "    \n",
    "    return ((preds.argmax(1)==gt).sum()/len(preds)).cpu().numpy()\n",
    "    \n",
    "\n",
    "def get_test_acc(emb_model, model, test_loader, feature_fn, device='cuda'):\n",
    "    eval_acc = []\n",
    "    eval_losses = []\n",
    "    for eval_batch in test_loader:\n",
    "        if len(eval_batch)>2:\n",
    "            _, ims, labels = eval_batch\n",
    "        else: \n",
    "            ims, labels = eval_batch\n",
    "        ims, labels = ims.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            features = feature_fn(emb_model, ims).squeeze()\n",
    "            preds = model(features)\n",
    "            val_acc = get_acc(labels.view(-1,), preds)\n",
    "        \n",
    "        eval_acc.append(val_acc)\n",
    "    \n",
    "    return np.mean(eval_acc)\n",
    "            # \n",
    "test_acc_orig = racc =  get_test_acc(model, imagebind_clf, test_loader, get_image_features, device=device,)\n",
    " \n",
    "print(test_acc_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupts_dict = {}\n",
    "corrupt_g_acc = []\n",
    "for cr in ['gaussian_noise', 'speckle_noise', 'impulse_noise', 'shot_noise', ]:\n",
    "    corrupts_dict[cr] = {}\n",
    "    for sev in [1, 2, 3, 4, 5]:\n",
    "        test_loader_corrupt = get_corrupt_loaders(batch_size=1024, corruption_type=cr, severity=sev, model_name='blip')\n",
    "        acc =  get_test_acc(model, imagebind_clf, test_loader_corrupt, get_image_features, device=device,)\n",
    "                                \n",
    "\n",
    "        corrupts_dict[cr][sev]=acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussian_noise': {1: 0.9197146,\n",
       "  2: 0.82722014,\n",
       "  3: 0.70214444,\n",
       "  4: 0.6376993,\n",
       "  5: 0.58301777},\n",
       " 'speckle_noise': {1: 0.955114,\n",
       "  2: 0.8844547,\n",
       "  3: 0.8393275,\n",
       "  4: 0.7380939,\n",
       "  5: 0.63478357},\n",
       " 'impulse_noise': {1: 0.9696628,\n",
       "  2: 0.94978875,\n",
       "  3: 0.92277783,\n",
       "  4: 0.8465541,\n",
       "  5: 0.757954},\n",
       " 'shot_noise': {1: 0.95297945,\n",
       "  2: 0.9128707,\n",
       "  3: 0.7808095,\n",
       "  4: 0.7160694,\n",
       "  5: 0.6023896}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('brn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5b4607d21dcc400ead18a1c2ca0189f0fcf8d976d586df05f937ecd8ea5ac01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
